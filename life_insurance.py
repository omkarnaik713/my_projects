# -*- coding: utf-8 -*-
"""Life Insurance

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EVqXavaAkCmo4TzHk0CNkGid6Ydo6_a9
"""

import pandas as pd
dataset = pd.read_csv('insurance.csv')

dataset.head()

dataset.info()

dataset.isnull().sum()

"""There are no null values in the dataset"""

# data preprocessing
# converting the columns from string categorical values to int categorical

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

# columns that need to be encoded are 'sex' , 'smoker' , 'region'
dataset['SEX'] = le.fit_transform(dataset['sex'])
dataset['Smoker'] = le.fit_transform(dataset['smoker'])
dataset['Region'] = le.fit_transform(dataset['region'])
dataset.drop(['sex','smoker','region'], inplace = True , axis = 1)

dataset.head()

dataset.drop('index',inplace = True , axis = 1)

import seaborn as sns
sns.heatmap(dataset)

dataset['SEX'].value_counts()

dataset['Smoker'].value_counts()

dataset['Region'].value_counts()

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

lr = LinearRegression()
rfr = RandomForestRegressor()

# splitting the data

x = dataset.drop('charges',axis =1)
y = dataset['charges']

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)

# training the model

lr.fit(x_train,y_train)
rfr.fit(x_train,y_train)

y_pred = lr.predict(x_test)

y_pred_rfr = rfr.predict(x_test)
y_pred_rfr

from sklearn.metrics import mean_squared_error, mean_absolute_error
print(mean_absolute_error(y_test,y_pred))

print(mean_squared_error(y_test,y_pred_rfr))

print(mean_absolute_error(y_test,y_pred_rfr))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators' : [50,75,100,125,150],
    'criterion' : ['squared_error','absolute_error','friedman_mse','poisson'],
}
rfr_gs = GridSearchCV(RandomForestRegressor(),param_grid,n_jobs=-1,verbose = 2, cv = 5)
rfr_gs.fit(x_train,y_train)
print("Best Parameters : ",rfr_gs.best_params_)

rfr_bm = RandomForestRegressor(n_estimators=100, criterion='poisson')
rfr_bm.fit(x_train,y_train)
print(mean_absolute_error(y_test,rfr_bm.predict(x_test)))
print(mean_squared_error(y_test,rfr_bm.predict(x_test)))

"""The difference in the error was minute which implies we will have to find the other hyperparameters which will improve the model.

Sandardizing the data to reduce the error
"""

from sklearn.preprocessing import StandardScaler

x_train_stand = x_train.copy()
x_test_stand = x_test.copy()

column_list = dataset.columns

for i in column_list:

  scale = StandardScaler().fit(x_train_stand)
  x_train_stand = scale.transform(x_train_stand)
  x_test_stand = scale.transform(x_test_stand)

x_train_stand

rfr_s = RandomForestRegressor(n_estimators = 100, criterion = 'poisson')
rfr_s.fit(x_train_stand,y_train)
print(mean_squared_error(y_test, rfr_s.predict(x_test_stand)))

, median_absolute_error
print(mean_absolute_error(y_test, rfr_s.predict(x_test_stand)))

